{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trafficSignRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jscVMLofeb1z",
        "outputId": "d504180f-5cac-4375-cd11-b4f8bff47e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gdrive/My\\ Drive/ComputerVision/train.zip\n"
      ],
      "metadata": {
        "id": "G8RVIH78Tc4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf \n",
        "from PIL import Image\n",
        "import os \n",
        "from skimage.filters import threshold_otsu\n",
        "from sklearn.model_selection import train_test_split \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout \n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "-ObVBbFFWJ_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "classes = 43 \n",
        "cur_path = os.getcwd()\n",
        "cur_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RhraSr73gGPd",
        "outputId": "838f3529-6c3d-4af5-fe33-d651ff0db18b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(classes): \n",
        "  path = os. path.join(cur_path,'train', str(i)) \n",
        "  images = os.listdir(path) \n",
        "  for a in images: \n",
        "     try:\n",
        "      image = cv2.imread(path + '/'+ a) \n",
        "      image = cv2.resize(image,(30,30))\n",
        "      #image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "      #image=cv2.equalizeHist(image)\n",
        "      image = np.array(image)\n",
        "      data.append(image)\n",
        "      labels.append(i)\n",
        "     except: \n",
        "        print(\"Error loading image\") \n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "HcxLGXJYqE4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t1, X_t2, y_t1, y_t2 = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "print(X_t1.shape, X_t2.shape, y_t1.shape, y_t2.shape)\n",
        "#Converting the labels into one hot encoding\n",
        "y_t1 = to_categorical(y_t1, 43)\n",
        "y_t2 = to_categorical(y_t2, 43)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFrCpTIrwr3K",
        "outputId": "a9e8936d-e8b1-40c8-cae6-657acf07e079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31367, 30, 30, 3) (7842, 30, 30, 3) (31367,) (7842,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def filter_image(image, mask):\n",
        "    r = image[:,:,0] * mask\n",
        "    g = image[:,:,1] * mask\n",
        "    b = image[:,:,2] * mask\n",
        "    return np.dstack([r,g,b])\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GJEvHcvOxTRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a function that applies thresholding to the images, but it turned out not to be beneficial to the end result\n",
        "\"\"\"\n",
        "def thresholding(images):\n",
        "    final_images=[]\n",
        "    for i in range(0,len(images)):\n",
        "        img=images[i]\n",
        "        img_rgb=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "        img_gray=cv2.cvtColor(img_rgb,cv2.COLOR_RGB2GRAY)\n",
        "        thresh = threshold_otsu(img_gray)\n",
        "        img_otsu  = img_gray < thresh\n",
        "        filtered = filter_image(img, img_otsu)\n",
        "        final_images.append(filtered)\n",
        "    return final_images\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "234SHA8pXJEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "final_images=thresholding(data)\n",
        "final_images = np.array(final_images)\n",
        "X_t1, X_t2, y_t1, y_t2 = train_test_split(final_images, labels, test_size=0.2, random_state=42)\n",
        "y_t1 = to_categorical(y_t1, 43)\n",
        "y_t2 = to_categorical(y_t2, 43)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hltaL-sQXNC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=X_t1.shape[1:]))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "#model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "#Compilation of the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vSF4HtmcXkWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eps = 20\n",
        "anc = model.fit(X_t1, y_t1, batch_size=32, epochs=eps, validation_data=(X_t2, y_t2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjTa6oTSXmcA",
        "outputId": "0be8cb45-ee31-426e-e832-391f4cfe39c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "981/981 [==============================] - 33s 33ms/step - loss: 2.5949 - accuracy: 0.3891 - val_loss: 0.9048 - val_accuracy: 0.7735\n",
            "Epoch 2/20\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.6087 - accuracy: 0.8254 - val_loss: 0.2833 - val_accuracy: 0.9260\n",
            "Epoch 3/20\n",
            "981/981 [==============================] - 33s 34ms/step - loss: 0.3474 - accuracy: 0.9015 - val_loss: 0.1448 - val_accuracy: 0.9577\n",
            "Epoch 4/20\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.2967 - accuracy: 0.9155 - val_loss: 0.1289 - val_accuracy: 0.9649\n",
            "Epoch 5/20\n",
            "981/981 [==============================] - 33s 34ms/step - loss: 0.2524 - accuracy: 0.9319 - val_loss: 0.1299 - val_accuracy: 0.9670\n",
            "Epoch 6/20\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.2290 - accuracy: 0.9352 - val_loss: 0.1494 - val_accuracy: 0.9690\n",
            "Epoch 7/20\n",
            "981/981 [==============================] - 32s 32ms/step - loss: 0.2307 - accuracy: 0.9383 - val_loss: 0.1250 - val_accuracy: 0.9685\n",
            "Epoch 8/20\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.2005 - accuracy: 0.9465 - val_loss: 0.0912 - val_accuracy: 0.9750\n",
            "Epoch 9/20\n",
            "981/981 [==============================] - 32s 32ms/step - loss: 0.2103 - accuracy: 0.9433 - val_loss: 0.0813 - val_accuracy: 0.9814\n",
            "Epoch 10/20\n",
            "981/981 [==============================] - 32s 32ms/step - loss: 0.1916 - accuracy: 0.9500 - val_loss: 0.0736 - val_accuracy: 0.9801\n",
            "Epoch 11/20\n",
            "981/981 [==============================] - 32s 32ms/step - loss: 0.1888 - accuracy: 0.9499 - val_loss: 0.0699 - val_accuracy: 0.9841\n",
            "Epoch 12/20\n",
            "981/981 [==============================] - 33s 34ms/step - loss: 0.1781 - accuracy: 0.9536 - val_loss: 0.0799 - val_accuracy: 0.9806\n",
            "Epoch 13/20\n",
            "981/981 [==============================] - 32s 32ms/step - loss: 0.2010 - accuracy: 0.9477 - val_loss: 0.0861 - val_accuracy: 0.9767\n",
            "Epoch 14/20\n",
            "981/981 [==============================] - 33s 33ms/step - loss: 0.1831 - accuracy: 0.9537 - val_loss: 0.1165 - val_accuracy: 0.9709\n",
            "Epoch 15/20\n",
            "981/981 [==============================] - 35s 35ms/step - loss: 0.1812 - accuracy: 0.9551 - val_loss: 0.0874 - val_accuracy: 0.9799\n",
            "Epoch 16/20\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.1714 - accuracy: 0.9564 - val_loss: 0.0657 - val_accuracy: 0.9834\n",
            "Epoch 17/20\n",
            "981/981 [==============================] - 32s 32ms/step - loss: 0.1874 - accuracy: 0.9571 - val_loss: 0.0807 - val_accuracy: 0.9797\n",
            "Epoch 18/20\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.1672 - accuracy: 0.9585 - val_loss: 0.0760 - val_accuracy: 0.9843\n",
            "Epoch 19/20\n",
            "981/981 [==============================] - 34s 35ms/step - loss: 0.1625 - accuracy: 0.9600 - val_loss: 0.1165 - val_accuracy: 0.9705\n",
            "Epoch 20/20\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.1762 - accuracy: 0.9571 - val_loss: 0.0879 - val_accuracy: 0.9814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "5YZL0tXlhbo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_labels=np.argmax(y_t2, axis=1)"
      ],
      "metadata": {
        "id": "fyJsOxxOLt6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.argmax(model.predict(X_t2), axis=-1)\n",
        "print(accuracy_score(rounded_labels, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NGGTlkPh8Pb",
        "outputId": "1c2463c1-9457-431c-f907-595566b0cf79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9813823004335629\n"
          ]
        }
      ]
    }
  ]
}